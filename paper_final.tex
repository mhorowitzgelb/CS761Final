\documentclass{article}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{color}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{bbm}
\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

\setlength{\parskip}{5pt}
\setlength{\parindent}{0pt}

\title{\rule{350pt}{5pt}\\ \textbf{An Extension of Optimal Teaching For Online Perceptrons} \\ \rule{350pt}{1pt}}


\author{
  \textbf{Max Horowitz-Gelb \qquad Gabriel Ferns}\\
  Department of Computer Sciences, University of Wisconsin-Madison\\
  \texttt{\{horowitzgelb, ferns\}@wisc.edu}\\
}

\newcommand{\learn}{\mathcal{A}_{w_0}^\eta}
\newcommand{\radian}{\text{radian}}


\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
  Optimal teaching is the task of constructing an efficient training set
  that teaches a learner some desired concept inside its concept class. Before
  \cite{perceptron}, analysis of optimal teaching was only focused on batch
  learners. \cite{perceptron} looked at the optimal teaching strategy of an
  online Perceptron with varying degrees of knowledge of the initial state of
  the learner. In this paper, we extend these results to environments where
  there is even less knowledge of the Perceptron's initial state, but the
  teacher is given extra powers to compensate. We present two teaching strategies that take advantage of unlabeled examples to teach a perceptron. We also analyze a another strategy in which a teacher has the ability to
  lie.
\end{abstract}

\section{Introduction}
In the real world, there are often scenarios where a teacher wishes to
embed a desired concept within a learner. Sometimes, the teacher can only
interact with the learner by providing the learner with a set of training examples.
The task of creating the smallest possible set of examples that
produces the desired concept in the learner is known as optimal teaching
\cite{machine_teaching} \cite{teaching_dimension}\cite{td_linear}. It has applications in education and security \cite{security}\cite{education} \cite{poisoning}. \cite{perceptron} looked for
the first time at optimal teaching in an online environment by finding the teaching dimension of an online perceptron. In this paper we look at the
optimal teaching of the same perceptron, but with a teacher that also possess
the ability to use unlabeled examples. An unlabeled example gives the teacher
knowledge of the learner's prediction about that example without altering the
learner's state. This is a reasonable power for any real-world teacher to
posses. We show that this added ability, with the exclusion of some worst case scenarios, allows the teacher to teach an
online perceptron in a zero-knowledge scenario that otherwise would have been
difficult.

The specific perceptron we are teaching is the online perceptron
designed for binary classification \cite{perceptron_algo}. It can learn any
linear decision boundary with mapping $x \to sign(\langle w, x \rangle)$, where
$x \in \mathbb{R}^d$ is in the input space and $w \in \mathbb{R}^d$
parameterizes the perceptron. Here, as in \cite{perceptron}, $sign(0) = -1$ for
completeness. The learning algorithm for the online perceptron is seen below.

\begin{algorithm}
\caption{Online Perceptron}
\begin{algorithmic}[1]
	\REQUIRE Initial weight vector $w_0 \in \mathbb{R}^d$, learning rate $\eta > 0$
	\FOR{$t \in 1$ ...}
    	\STATE receive $x_t$
    	\STATE predict $\hat{y}_t = sign(\langle w_{t-1} , x_t \rangle)$
    	\STATE receive $y_t$
    	\STATE $w_t \leftarrow w_{t-1} + \mathbbm{1}_{y_t \langle w_{t-1} , x_t \rangle \leq 0} \eta x_t$
    \ENDFOR
\end{algorithmic}
\end{algorithm}

Because $w_0$ and $\eta$ affect the Perceptron's learning, knowledge of them is
critical to being able to teach an online Perceptron learner. \cite{perceptron}
looked at teaching a perceptron with, and without knowledge of $w_0$. Here we
look at the situation where $w_0$ is known, but the learning rate $\eta$ is
unknown. We also look at the most challenging case, when both $w_0$ and $\eta$
are unknown at the start of teaching. 

\section{Approximate Teaching Dimension}
\cite{perceptron}  defined an approximate teaching dimension for cases where
the exact teaching dimension was infinite, but one could approximately teach a concept within $\epsilon$ distance. For perceptrons, the distance metric used was simply the 1 minus the cosine angle between $w^*$ and $\learn(S)$
$$
1 -\frac{\langle \learn(S), w^* \rangle}{\lVert \learn(s) \rVert \lVert w^* \rVert} \leq \epsilon
$$

Then let $\mathbb{T}_\epsilon$ be the set of $\epsilon$-approximate teaching strategies for a decision boundary $w^*$. Then
$$
TD_\epsilon(w^*, \learn) = \min_{t \in 
\mathbb{T}_\epsilon} \max_{w_0 \in 
\mathbb{R}^d} \lvert t(w_0) \rvert
$$
where $\learn$ is the learning algorithm and $S$ is the training sequence. 
\cite{perceptron} showed that when $w_0$ was unknown but $\eta$ was known, $TD_\epsilon(w^*, \learn) = 3$

\section{Approximate Teaching with Unkown $\eta$}
Now we look at the scenario where the initial weight vector is known but the learning rate is unknown and bounded.

\subsection{Using Unlabeled Examples}
Before, the teaching dimension was only analyzed with labeled examples. Here we relax this constraint and allow unlabeled examples to be used in the teaching sequence. Now we redefine $\mathbb{S}$ to be the set of all sequences of labeled and unlabeled examples. And for any $S \in \mathbb{S}$
$$
\learn(S) = \learn(S \setminus \{s \in S : s = (x, ?)\} )
$$

\subsection{Algorithm for bounding $\eta$}
With the ability to teach with unlabeled examples, below shows the optimal algorithm for bounding $\eta$ within a desired length, under the conditions that $\eta$ is bounded and $w_0$ is known a priori.

\begin{algorithm}
\caption{Bounding $\eta$ within $\epsilon$ }
\begin{algorithmic}[1]
	\REQUIRE $\epsilon$ , lower bound $\eta_{\min} > 0$, upper bound $\eta_{\max} < \infty$ and $w^*$
	\STATE Select $(x_1 , y_1)$ s.t. $sign(\langle w^* , x_1 \rangle) = y_1 = -1 = 
	-sign(\langle w_0 , x_1 \rangle )$
	\STATE Give $(x_1, y_1)$ to the perceptron and allow to update.
	\STATE $\alpha \leftarrow \eta_{\min}$
	\STATE $\beta \leftarrow \eta_{\max}$
	
	\WHILE{$\beta - \alpha > \epsilon$}
		\STATE Select $ x_2$ s.t. $\langle w_0 , x_2 \rangle \neq 0, \langle x_1 , x_2 \rangle \neq 0$ and $\langle w_0, x_2 \rangle - \frac{\beta - \alpha}{2}\langle x_1, x_2 \rangle = 0$
		\STATE Let the perceptron predict $\hat{y}$ for $x_2$
		\IF{$\hat{y} = 1$}
			\STATE $ \beta \leftarrow \frac{\beta - \alpha}{2}$ 		
		\ELSE
			\STATE $ \alpha \leftarrow \frac{\beta - \alpha}{2}$ 
		\ENDIF	
	\ENDWHILE   
	\RETURN $(\alpha , \beta)$
\end{algorithmic}
\end{algorithm} 

\textbf{Theorem 1.}
\textit{
If given a perceptron with known starting parameter $w_0$, desired parameter $w^*$, and unknown 
learning rate $\eta \in [\eta_{\min} , \eta_{\max}]$, then for given $\epsilon > 0$, \textbf{Algorithm 2} can guarantee $\eta \in 
[\alpha, \beta]$ such that $\beta - \alpha \leq \epsilon$ using $1 + \lceil \log_2(\frac{\eta_
{\min} - \eta_{\max}}{\epsilon})\rceil$ examples.}

\textit{Proof.}
Assume $w_0 \neq cw^*$ for arbitrary $c > 0$, then there exists an $(x_1, y_1)$ such that $\text{sign}(\langle w^*,x_1 \rangle) = y_1 = -1$ and $\text{sign}(\langle w_0,x_1 \rangle) = -y_1$.


Then give $(x_1, y_1)$ to the learner and then after training update,
$$
w_1 = w_0 + \eta x_1
$$

Then grab an unlabeled $x_2$ such that
$\langle w_0,x_2 \rangle \neq 0$, $\langle x_1, x_2 \rangle \neq 0$
and 
$$
\langle w_0,x_2 \rangle - \frac{\eta_{\max} - \eta_{\min}}{2} \langle x_1, x_2 \rangle = 0
$$
There will always an $x_2$ with this property.


Then probe the learner with $x_2$. If the learner outputs $-1$ then
$\eta \in (\frac{\eta_{\max} - \eta_{\min}}{2} , \eta_{\max}]$, else 
$\eta \in [\eta_{\min},\frac{\eta_{\max} - \eta_{\min}}{2}]$

After the first labeled example , the length of the bound on $\eta$ is halved which each unlabeled example given. So one can see that with $n + 1$ examples the length of the bound on $\eta$ is $\frac{\eta_{\max} - \eta_{\min}}{2 ^ n }$. So to achieve a bound length of $\epsilon$ one needs
$ 1 + \lceil \log_2 ( \frac{\eta_
{\min} - \eta_{\max}}{\epsilon} ) \rceil$ examples.

\subsection{Teaching Dimension for Unknown $\eta$}

\textbf{Theorem 2.}
\textit{ If $w_0$ is known , $\lVert w_0 \rVert \leq b < \infty$ and $ 0 < \eta_{\min} \leq \eta \leq \eta_{\max} < \infty$ 
then $\mathbb{T}_{\epsilon}(w^*, \learn)  \leq 2 + \lceil \log_2 \frac{\eta_{\max} - \eta_{\min}}{2\epsilon\eta_{\max}}  \rceil$
}
\\
\\
\textit{Proof.}
Assume WLOG $\lVert w^* \rVert = 1$.

Pick $(x_1,y_1)$ such that $y_1 = -1$, $\lVert x_1 \rVert = \frac{2 b}{\epsilon \eta_{\min}}$ and $\langle x_1 , w^* \rangle = 0$.

Use this $(x_1, y_1)$ in \textbf{Algorithm 2} to get a bound on $\eta$ such that $\eta \in [\alpha , \beta]$ and $\beta - \alpha \leq 2\epsilon \eta_{\max}$

Then let $x_2 = \frac{2 b}{\epsilon (\beta + \alpha)/2}w^* + x_1$.
It should be clear that then that $sign(\langle w* , x_2 \rangle) =  y_2 = 1$

Then realize that
$w_1 = w_0 - \eta x_1$

So
$$
y_2 \langle w_1, x_2 \rangle  = \bigg\langle \frac{2 b}{\epsilon (\beta + \alpha) /2} w^* + x_1 , w_0 - \eta x_1 \bigg\rangle
= \bigg\langle \frac{2 b}{\epsilon (\beta + \alpha) /2} w^* + x_1 , w_0  \bigg\rangle - \eta \lVert x_1 \rVert^2
$$
$$
\leq \bigg( \frac{2 b}{\epsilon (\beta + \alpha) /2} \lVert w^* \rVert + \lVert x_1 \rVert \bigg ) b - \eta \lVert x_1 \rVert^2
\leq \frac{4 b ^2}{\epsilon \eta_{\min}} - \eta \frac{4 b^2}{\epsilon^2 \eta_{\min}^2}
\leq \frac{4 b^2}{\epsilon \eta_{\min}}  -  \frac{4 b^2}{\epsilon^2 \eta_{\min}}
$$
which is less than $0$ for $\epsilon < 1$, so $(x_2 , y_2)$ will cause the perceptron to update.

Then,
notice that $w_2 = w_0 +\eta \frac{2  b}{\epsilon (\beta + \alpha)/2} w^*$

Then 
$$
\frac{\langle w_2, w^* \rangle}{\lVert w_2 \rVert \lVert w^* \rVert} = \frac{
\frac{\eta 2  b}{\epsilon (\beta + \alpha)/2} \lVert w^* \lVert ^2 + \langle w_0, w^* \rangle}{\lVert w_2 \rVert}
$$ 
$$
\geq \frac{\frac{\eta 2  b}{\epsilon (\beta + \alpha)/2} - b}{b +\frac{\eta 2  \lVert w_0 \rVert}{\epsilon (\beta + \alpha)/2} }
= 1 - \frac{2 b}{b +\frac{\eta 2  b}{\epsilon (\beta + \alpha)/2} }
= 1 - \frac{2b}{b \epsilon + \frac{\eta 2  b}{(\beta + \alpha)/2} } \epsilon
$$
$$
\geq  1 - \frac{2b}{b \epsilon + \frac{\eta 2  b}{\eta_{\max} - (\beta - \alpha) / 2} } \epsilon
\geq  1 - \frac{2b}{b \epsilon + \frac{\eta 2  b}{\eta_{\max} (1-\epsilon)} } \epsilon
\geq 1 - \frac{2b}{b \epsilon + \frac{ 2  b}{(1-\epsilon)} } \epsilon
$$
$$
\geq 1 - \epsilon
$$

Therefore 
$\mathbb{T}_\epsilon(w^* ,\learn) \leq  2 + \lceil \log_2 \frac{\eta_{\max} - \eta_{\min}}{2\epsilon\eta_{\max}}  \rceil$

\subsection{Tightness of Bound}
We believe the bound in \textbf{Theorem 2} is tight. There are examples for which a single labeled example will not be able to guarantee our $\epsilon$ upper bound without a better bound on the learning rate. And we believe \textbf{Algorithm 2} is optimal for bounding the learning rate. Further work will need to be done to prove the tightness of \textbf{Theorem 2}.

\section{Discussions of the teaching dimension for unknown $\eta$ and $w_0$}

We present an algorithm that teaches the desired concept to the Perceptron
learner when we know neither the learning rate, nor the initial weight vector of
our perceptron learner. The algorithm works well in general, but there is a very
unlikely case that will cause the number of unsupervised queries to diverge to
infinity. We also discuss a potential problem in the definition of the teaching
dimension and prove an upper bound on the teaching dimension in this setting
given an optimal algorithm for bounding $\eta$.

\subsection{$\epsilon$-Bounding the angle of $w_0$}
Our algorithm will only consider the decision boundary and the weight vector of
the Perceptron in two dimensions. In other words, we are considering the plane

defined by,
\[
  \begin{bmatrix}
    a & b & 0 & \cdots & 0
  \end{bmatrix} ^ \top
  \textnormal{where}
  \ a, b \in \mathbb{R}
\]
The decision boundary of the Perceptron passes through the origin, so it will
also pass through the origin of this plane and create a linear decision
boundary.
\\

In order to proceed, we must define an operation that creates an
$\epsilon$-Bound around the angle of $w_o$ in the plane. It works by iteratively
partitioning the plane with unlabeled examples. For convenience, let $(a,b)$
denote a point in said plane. Let $ang(x,y)$ denote the angle between $x$ and
$y$. Let $mid(x, y)$ be the midpoint between $x$ and $y$ on the unit circle
($x$ and $y$ have the same magnitude). Let $test(\alpha)$ be an unsupervised
check of $\alpha$.

\begin{algorithm}
\caption{Bounding the angle of $w_0$}
\begin{algorithmic}[1]
	\REQUIRE $\epsilon$
  \STATE Compute $test((0,1))$, $test((1,0))$, and $test((0,-1))$

  \COMMENT{One of these will be different from the others, or $w_0 \in
  \{(1,0), (-1,0)\}$, in which case we're done.}
  \STATE $\alpha \leftarrow $ the different one, $\beta \leftarrow $ the one
  next to $\alpha$.
  \FOR{$i \leftarrow \frac{1}{4}$; $i > \epsilon$; $ i \leftarrow \frac{i}{2}$}
  \IF{$test(mid(\alpha,\beta)) \ != test(\alpha)$}
  \STATE $\beta \leftarrow mid(\alpha, \beta)$
  \ELSE
  \STATE $\alpha \leftarrow mid(\alpha, \beta)$
  \ENDIF
  \ENDFOR
  \RETURN $\alpha$, $\beta$
  
\end{algorithmic}
\end{algorithm}


This gets us a bound around the angle of $w_0$ in time $\ceil{log(\frac{1}{\epsilon})} +
1$.

\subsection{$\epsilon$-Bounding $\eta$}

Now that we know that we can move and bound the angle of $w_0$, we can bound
$\eta$. The algorithm works by giving the perceptron a ``large enough'' update,
two times. Because the update is vector addition, the size of the update is a
linear combination of $\eta$ and $\lVert w_0 \rVert$. With two equations and two
unknowns, we can derive both $\eta$ and $\lVert w_0 \rVert$. Using basic trig,
we get,

\[
  \begin{cases}
    \lVert w_0 \rVert * \tan(\theta_1) + \eta * \lVert x \rVert (\tan(\theta_1)  
    \cos{\phi} - \sin{\phi}) = 0 \\

    \lVert w_0 \rVert * \tan(\theta_2) + \eta * 2 \lVert x \rVert (\tan(\theta_2)
    \cos{\phi} - \sin{\phi}) = 0 \\
  \end{cases}
\]
\textit{where $\theta_1, \theta_2$ are the angles of the updated $w$'s with
  $w_0$, $\phi$ is the angle of the training case with $w_0$, and $x$ is our
  training example.}


\begin{algorithm}
\caption{Bounding $\eta$}
\begin{algorithmic}[1]
	\REQUIRE $\epsilon'$: desired bound around the concept $w^*$
  \STATE $\alpha_1, \beta,_1 \leftarrow$ bounds around $w_0$ such that $w^*$ is not
  inside it

  \COMMENT{If we detect that $ang(\alpha_1, \beta_1) < \epsilon'$, we can quit the
    whole teaching procedure because the learner knows the concept.}
  \STATE $x' \leftarrow $ the most perpendicular vector to $mid(\alpha_1, \beta_1)$
  that causes an update
  \STATE $v \leftarrow$ constant ``large enough'' to make the perceptron update
  \STATE $teach(x' * v)$
  \STATE $\alpha_2, \beta_2 \leftarrow$ ``small enough'' bound around $w$
  \STATE $teach(x' * v)$
  \STATE $\alpha_3, \beta_3 \leftarrow$ ``small enough'' bound around $w$
  \STATE Solve the linear equation defined above 8 times using every combination of
  $\alpha$ and $\beta$. The $\epsilon$-Bound is the worst case of these.
\end{algorithmic}
\end{algorithm}

The problem with this algorithm appear in step 3; it is possible to come up with
concrete definitions for Steps 2, 5, 7. We can construct a case where
$\alpha_1$ and $\beta_1$ are as close as possible, without being $ < \epsilon'$,
and $w^*$ is arbitrarily close to $\alpha$. This situation can require
arbitrarily tight bounds on the angle of $w_0$, requiring arbitrarily many
unsupervised queries.
\subsection{Discussions of the Definition of Teaching Dimension}
Given that the algorithm works well in general, but diverges in certain pathological
cases, we suggest that an extension of the concept of the teaching dimension
could be useful for dealing with Machine Teaching in more complex settings.
Instead of Minmaxing the number of examples, we propose that the expected value
of a teaching algorithm is a more interesting metric. There is a parallel to
statistical learning theory: instead of using the ``minimax
rule'' to minimize the Risk, it is better to minimize the expected Risk.

\subsection{Main Result}
\textbf{Theorem 4.} 
\textit{With unknown $w_0$ such that $\lVert w_0 \rVert \leq b < \infty$
and unknown $\eta$ such that $0 < \eta_{\min} \leq \eta \leq \eta_{\max} < \infty$ then 
$
\mathbb{T}_\epsilon(w^* , \learn) \leq 3 + T_{\text{bound}}(2\epsilon \eta_{\max})
$
where $T_{\text{bound}}(2\epsilon \eta_{\max})$ is the worst case number of examples needed to bound $\eta \in [\alpha , \beta]$ s.t. $\beta - \alpha \leq 2\epsilon \eta_{\max}$
}
\\
\\
\textit{Proof.}

First bound $\eta$ such that $ \alpha \leq \eta \leq \beta$ and $\beta - \alpha \leq 2\epsilon \eta_{\max}$

Then WLOG assume $\lVert w^* \rVert = 1$. Then pick an $x_1$ such that 
$\lVert x_1 \rVert = \frac{2b}{\epsilon (\beta + \alpha)/2}$ and $\langle w^*, x_1 \rangle = 0$. Such an $x_1$ always exists. Then, let $x'_1 = -x_1.$ Then $y_1 = y'_1 = \text{sign}(\langle w*, x_1 \rangle) = -1$.  Then since $y_1 = y'_1$ then the perceptron must make an error on one of the examples. So first give $(x_1, y_1)$ to the perceptron.

\underline{Case 1}: If $(x_1, y_1)$ causes an update then $w_1 = w_0 - \eta x_1$. 
Then select at the second iteration an $x_2 = \frac{2b}{\epsilon (\beta + \alpha)/2}$. Using the same logic from theorem 2, we can see that this will give us our desired $\epsilon$ approximate $w_2$. 

\underline{Case 2}: If $(x_1, y_1)$ did not cause and update then set $x_2 = x'_1$ , $y_2 = y'_1$ and $x_3 = \frac{2b}{\epsilon (\beta + \alpha)/2}w^* + x_2$. Using very similar logic to how Case 1 used Theorem 2, we can see that this will also get us the desired $\epsilon$ approximate $w_3$.

In Case 1 we require 2 examples and and Case 2 we require 3, so including the examples needed to bound $\eta$ we get that 
$$
\mathbb{T}_\epsilon(w^*, \learn) \leq 3 + T_{\text{bound}}(2\epsilon \eta_{\max})
$$

\section{Ability to Lie}
Allowing the teacher to lie, or give $(x,y)$ that disagree with $w^*$, make teaching the learner very easy. In fact in this scenario, the approximate teaching dimension is $2$.
\\
\\
\textbf{Theorem 5.} \textit{
Let $w_0$, $\eta$ be unknown with $\lVert w_0 \rVert \leq b$ and $0 < \eta_{\min} \leq \eta$.
Then with the ability to lie, $\mathbb{T}_{\epsilon}(w^*, \learn) = 2$
}
\\
\\
\textit{Proof.}
WLOG assume $\lVert w^* \rVert = 1$
Select an $x_1 = \frac{b(2-\epsilon)}{\eta_{\min} \epsilon}w^*, \qquad y_1 = -1$
Then give $(x_1 , y _1)$ to the perceptron.
Then let $x_2 = 2x_1, \qquad y_2 = 1$ and give $(x_2, y_2)$ to the perceptron.

Then there are two cases.

\underline{Case 1:} The perceptron incorrectly predicts $y = 1$ for $x_1$.

Then 
$
w_1 = w_0 - \frac{\eta b(2-\epsilon)}{\eta_{\min} \epsilon}w^*
$

Then 
$$y_2 \langle w_1, x_2 \rangle
 = \langle w_0, 2x_1 \rangle - 2\frac{(\eta b(2-\epsilon))^2}{(\eta_{\min}\epsilon)^2}
$$
$$
 \leq 2b\frac{\eta b(2-\epsilon)}{\eta_{\min}\epsilon}
-  2\frac{(\eta b(2-\epsilon))^2}{(\eta_{\min}\epsilon)^2} 
$$
$$
\leq 2\frac{\eta b^2(2-\epsilon)}{\eta_{\min}\epsilon}
-  2\frac{\eta (b(2-\epsilon))^2}{\eta_{\min}\epsilon^2}
< 0 \qquad \text{ for } \epsilon < 0
$$
Therefore $(x_2, y_2)$ causes and update and
$w_2 =  w_0 + \frac{\eta b(2-\epsilon)}{\eta_{\min} \epsilon}w^* $

Then
$$
\frac{\langle w_2 , w^* \rangle}{\lVert w_2 \rVert \lVert w^* \rVert} = \frac{\frac{\eta b(2-\epsilon)}{\eta_{\min} \epsilon} + \langle w_0, w^* \rangle}{\lVert w_2 \rVert} \geq \frac{\frac{\eta b(2-\epsilon)}{\eta_{\min} \epsilon} - b}{b + \frac{\eta b(2-\epsilon)}{\eta_{\min} \epsilon}}
$$
Which implies
$$
1 - \frac{\langle w_2 , w^* \rangle}{\lVert w_2 \rVert \lVert w^* \rVert} \leq \frac{2b}{b + \frac{\eta b(2-\epsilon)}{\eta_{\min} \epsilon}}
\leq
\frac{2}{1 + \frac{2-\epsilon}{\epsilon}} = \epsilon
$$

\underline{Case 2:} $(x_1, y_1)$ does not cause an update.

Then clearly $(x_2, y_2)$ will cause an update and
$$
w_2 = w_0 + 2\frac{\eta b(2-\epsilon)}{\eta_{\min} \epsilon}w^* 
$$
so,
$$
\frac{\langle w_2 , w^* \rangle}{\lVert w_2 \rVert \lVert w^* \rVert} = 2\frac{\frac{\eta b(2-\epsilon)}{\eta_{\min} \epsilon} + \langle w_0, w^* \rangle}{\lVert w_2 \rVert} \geq \frac{\frac{\eta b(2-\epsilon)}{\eta_{\min} \epsilon} + \langle w_0, w^* \rangle}{\lVert w_2 \rVert} \geq 1 - \epsilon
$$

We have thus shown that we can get an $\epsilon$ approximate bound with only 2 examples. It should be clear that this is impossible to do with $1$ example since without knowledge of $w_0$ there exists no $(x_1, y_1)$ that can guarantee the perceptron will update.

So 
$
\mathbb{T}_{\epsilon}(w^*, \learn) = 2
$

\textbf{Corrolary}
\textit{
Theorem 5 also shows that with known $\eta$ and ability to lie the approximate teaching dimension is still 2. This is 1 less the the $\epsilon$ approximate Teaching dimension where we cannot lie. \cite{perceptron}
}

\section{Discussion}
Here we've shown some interesting bounds. Though not all tight they still highlight some of the security risks of perceptrons. If a perceptron were used on a web-server, any of these algorithms would be efficient enough to hack the perceptron to believe whatever decision boundary we like. As well these findings highlight the power of lying in Machine Teaching. With the ability to lie, teaching a perceptron becomes trivial. One further venture would be to look into other learning algorithms that could be taught efficiently with lying. 


\small
\bibliography{paper_bib}
\bibliographystyle{plain}


\end{document}